{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from googleapiclient.discovery import build\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API key for YouTube Data API\n",
    "api_key = 'YOUR_KEY_HERE'\n",
    "\n",
    "# Initialize VADER sentiment analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Function to extract YouTube video ID from trailer URL\n",
    "def extract_video_id(url):\n",
    "    if not url or pd.isna(url): \n",
    "        return None\n",
    "    match = re.search(r'v=([^&]*)|embed/([^?]*)', url)\n",
    "    if match:\n",
    "        return match.group(1) or match.group(2)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fetch YouTube comments\n",
    "def fetch_comments(youtube, video_id, max_results=100):\n",
    "    comments = []\n",
    "    try:\n",
    "        request = youtube.commentThreads().list(\n",
    "            part=\"snippet\",\n",
    "            videoId=video_id,\n",
    "            maxResults=max_results,\n",
    "            textFormat=\"plainText\"\n",
    "        )\n",
    "        while request:\n",
    "            response = request.execute()\n",
    "            for item in response['items']:\n",
    "                comment = item['snippet']['topLevelComment']['snippet']['textDisplay']\n",
    "                comments.append(comment)\n",
    "            request = youtube.commentThreads().list_next(request, response)  # Handle pagination\n",
    "            if len(comments) >= max_results:\n",
    "                break\n",
    "    except Exception as e:\n",
    "        pass\n",
    "    return comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute average sentiment score\n",
    "def compute_sentiment(comments):\n",
    "    if not comments:\n",
    "        print(\"No comments found.\")\n",
    "        return None  # Return None if no comments are available\n",
    "\n",
    "    # Calculate compound scores for all comments\n",
    "    scores = [analyzer.polarity_scores(comment)['compound'] for comment in comments]\n",
    "    \n",
    "    # Calculate the raw average of the scores\n",
    "    raw_average = sum(scores) / len(scores) if scores else 0.0\n",
    "\n",
    "    return raw_average\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_example_comment(comments, target_score):\n",
    "    if not comments:\n",
    "        return None\n",
    "\n",
    "    # Compute sentiment scores for all comments\n",
    "    scored_comments = [(comment, analyzer.polarity_scores(comment)['compound']) for comment in comments]\n",
    "\n",
    "    # Find the comment with the closest sentiment score to the target\n",
    "    closest_comment = min(scored_comments, key=lambda x: abs(x[1] - target_score))\n",
    "\n",
    "    # Limit comment to two sentences\n",
    "    truncated_comment = \".\".join(closest_comment[0].split(\".\")[:2]).strip()\n",
    "\n",
    "    # If the comment is longer than 90 characters, truncate and add \"...\"\n",
    "    if len(truncated_comment) > 130:\n",
    "        truncated_comment = truncated_comment[:127] + \"...\"\n",
    "\n",
    "    return truncated_comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process each movie trailer\n",
    "def process_trailers(api_key, df):\n",
    "    from googleapiclient.errors import HttpError\n",
    "\n",
    "    youtube = build('youtube', 'v3', developerKey=api_key)\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        video_url = row.get('trailer', None)\n",
    "        video_id = extract_video_id(video_url)\n",
    "\n",
    "        if not video_id:\n",
    "            df.at[index, 'sentiment_score'] = None\n",
    "            df.at[index, 'comment'] = None\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # Fetch comments and compute sentiment\n",
    "            comments = fetch_comments(youtube, video_id)\n",
    "            \n",
    "            # If comments are fetched, compute sentiment score and example comment\n",
    "            if comments:\n",
    "                sentiment_score = compute_sentiment(comments)\n",
    "                df.at[index, 'sentiment_score'] = sentiment_score\n",
    "\n",
    "                example_comment = fetch_example_comment(comments, sentiment_score)\n",
    "                df.at[index, 'comment'] = example_comment\n",
    "            else:\n",
    "                # No comments available\n",
    "                df.at[index, 'sentiment_score'] = None\n",
    "                df.at[index, 'comment'] = None\n",
    "\n",
    "        except HttpError as e:\n",
    "            # Handle cases where comments are disabled\n",
    "            df.at[index, 'sentiment_score'] = None\n",
    "            df.at[index, 'comment'] = None\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and scale sentiment scores using z-scores and sigmoid function\n",
    "def calculate_scaled_scores(df):\n",
    "    scores = df['sentiment_score'].dropna()\n",
    "\n",
    "    # Calculate mean and standard deviation for z-scores\n",
    "    mean = scores.mean()\n",
    "    std = scores.std()\n",
    "\n",
    "    # Apply z-score normalization\n",
    "    def z_score(x):\n",
    "        return (x - mean) / std if std != 0 else 0\n",
    "\n",
    "    z_scores = scores.apply(z_score)\n",
    "\n",
    "    # Apply sigmoid function to scale z-scores to [0, 1]\n",
    "    def sigmoid(x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    scaled_scores = z_scores.apply(sigmoid)\n",
    "\n",
    "    # Truncate to 2 decimal places and pad with zeros\n",
    "    def format_score(score):\n",
    "        return f\"{score:.2f}\"\n",
    "\n",
    "    df['sentiment_score'] = df['sentiment_score'].apply(\n",
    "        lambda x: format_score(sigmoid(z_score(x))) if pd.notna(x) else None\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"csvs\", exist_ok=True)\n",
    "\n",
    "franchise_csvs = [file for file in os.listdir(\"csvs\") if file.endswith('_movies.csv')]\n",
    "for franchise_csv in franchise_csvs:\n",
    "    franchise_name = franchise_csv.replace('_movies.csv', '')\n",
    "    csv_path = os.path.join(\"csvs\", franchise_csv) \n",
    "\n",
    "    movies = pd.read_csv(csv_path)\n",
    "    movies['sentiment_score'] = None  # Add a new column for sentiment scores\n",
    "    movies['comment'] = None  # Add a new column for sentiment scores\n",
    "\n",
    "    movies = process_trailers(api_key, movies)\n",
    "    movies = calculate_scaled_scores(movies)\n",
    "    filename = f\"csvs/{franchise_name}_movies.csv\"\n",
    "    movies.to_csv(filename, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
